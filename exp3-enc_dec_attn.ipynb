{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "contest3-enc-dec",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDjyeJGS1WJVwKo56XPapZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsatp/NLP-contest3/blob/main/exp3-enc_dec_attn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTGtpj3MIB41",
        "outputId": "5287c9ee-b864-4f90-a692-39665336d07c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-contest3'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 23 (delta 7), reused 23 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (23/23), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LGWy5VGVk6TXz_ZaYwGBvwJc5vFBzeZe\n",
            "To: /content/data.zip\n",
            "100% 24.1M/24.1M [00:00<00:00, 26.4MB/s]\n",
            "Archive:  /content/data.zip\n",
            "  inflating: dev_auto_tok.tsv        \n",
            "  inflating: dev_entities.json       \n",
            "  inflating: newly_tokenized/dev_auto_tok.tsv  \n",
            "  inflating: newly_tokenized/dev_entities.json  \n",
            "  inflating: newly_tokenized/train_auto_tok.tsv  \n",
            "  inflating: newly_tokenized/train_entities.json  \n",
            "  inflating: raw/dev_set.txt         \n",
            "  inflating: raw/test_set.txt        \n",
            "  inflating: train_auto_tok.tsv      \n",
            "  inflating: train_entities.json     \n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/samsatp/NLP-contest3.git\n",
        "\n",
        "!gdown 1LGWy5VGVk6TXz_ZaYwGBvwJc5vFBzeZe\n",
        "!unzip /content/data.zip\n",
        "!rm /content/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.11.2\n",
        "!mkdir /content/result\n",
        "!mkdir /content/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ro0Yvn61_RD",
        "outputId": "4e4c8fbf-2a0f-4982-b29b-f006d2027a64"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.11.2\n",
            "  Downloading tensorflow_addons-0.11.2-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.11.2) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.11.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib  \n",
        "preprocess = importlib.import_module(\"NLP-contest3.util.preprocess\")\n",
        "lst20utils = importlib.import_module(\"NLP-contest3.lst20utils\")"
      ],
      "metadata": {
        "id": "OHUrOIHiIUht"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seqs = preprocess.get_sequence(\"/content/train_auto_tok.tsv\")\n",
        "dev_seqs = preprocess.get_sequence(\"/content/dev_auto_tok.tsv\")\n",
        "\n",
        "X_train_raw, Y_train_raw = ['|'.join([e[0] for e in row]) for row in train_seqs], [[e[1] for e in row] for row in train_seqs]\n",
        "X_dev_raw, Y_dev_raw = ['|'.join([e[0] for e in row]) for row in dev_seqs], [[e[1] for e in row] for row in dev_seqs]"
      ],
      "metadata": {
        "id": "LGYWA23G2CT_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = ['<BOS>', 'I_LOC', 'B_LOC', 'B_MEA', 'B_NUM', 'I_ORG', 'I_DES', 'I_MEA', 'B_TRM', 'B_DTM', 'B_DES', 'B_BRN', 'I_PER', 'I_NUM', 'B_ORG', 'I_DTM', 'I_BRN', 'B_PER', 'I_TRM', 'I_TTL', 'B_TTL']"
      ],
      "metadata": {
        "id": "x38vMJPOCHX6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_raw[0], Y_train_raw[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq_MRDTK5CdQ",
        "outputId": "a1195c87-6d9b-429e-8c0f-8565f227ee15"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ธรรมนูญ|แชมป์|สิงห์|คลาสสิก|กวาด|รางวัล|แสน|สี่|หมื่น|บาท',\n",
              " ['B_PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "class SeqData:\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X  # List of texts\n",
        "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "                            filters='',\n",
        "                            lower=False,\n",
        "                            split='|',\n",
        "                            char_level=False,\n",
        "                            oov_token='<OOV>'\n",
        "                        )\n",
        "        self.ne_stringLookup = tf.keras.layers.StringLookup(\n",
        "                            max_tokens=None,\n",
        "                            num_oov_indices=1,\n",
        "                            mask_token='O',\n",
        "                            oov_token='<OOV>',\n",
        "                            vocabulary=tags,\n",
        "                            output_mode='int',\n",
        "                            sparse=False,\n",
        "                            pad_to_max_tokens=False\n",
        "                        )\n",
        "        self.tokenizer.fit_on_texts(X)\n",
        "    \n",
        "    def padding(self, seqs, dtype='int32', value=0.0):\n",
        "        return tf.keras.preprocessing.sequence.pad_sequences(seqs, padding='post', dtype=dtype, value=value)\n",
        "\n",
        "    def preprocess_ne_seq(self, seq):\n",
        "        seq.insert(0, '<BOS>')\n",
        "        return seq\n",
        "\n",
        "    def get_bool_mask(self, seqs):\n",
        "        mask = tf.ragged.constant(seqs)\n",
        "        return tf.ones_like(mask, dtype='int32').to_tensor(default_value=0)\n",
        "\n",
        "    def load_dataset(self, X, Y, BATCH_SIZE=64):\n",
        "\n",
        "        # create boolean mask\n",
        "        Y = [self.preprocess_ne_seq(e) for e in Y]\n",
        "        bool_mask = self.get_bool_mask(Y)\n",
        "\n",
        "        # preprocess X\n",
        "        tokens = self.tokenizer.texts_to_sequences(X)\n",
        "        tokens = self.padding(tokens)\n",
        "\n",
        "        # preprocess Y\n",
        "        padded_Y = self.padding(Y, dtype=object, value='O')\n",
        "        targets = self.ne_stringLookup(padded_Y)\n",
        "\n",
        "        # create dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((tokens, targets, bool_mask))\\\n",
        "                    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "        return dataset, bool_mask, self.tokenizer, self.ne_stringLookup"
      ],
      "metadata": {
        "id": "5Ha7YG5R2jB6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_creator = SeqData(X_train_raw, Y_train_raw)\n",
        "\n",
        "train_dataset, train_bool_mask, tokenizer, ne_stringLookup = data_creator.load_dataset(X_train_raw, Y_train_raw)\n",
        "dev_dataset, dev_bool_mask, _, _ = data_creator.load_dataset(X_dev_raw, Y_dev_raw)"
      ],
      "metadata": {
        "id": "C5QjaaaF8C64"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_X_batch, example_Y_batch, example_mask = next(iter(train_dataset))\n",
        "print(example_X_batch.shape, example_Y_batch.shape, example_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNtOLgDzBguN",
        "outputId": "c3796dc7-a2f0-48b7-c04f-ac2e77fde316"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 930) (64, 932) (64, 932)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_Y_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZNEBmJcCXVA",
        "outputId": "e9dd8ad0-8a25-4f8f-9f01-47b4c937823a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 932), dtype=int64, numpy=\n",
              "array([[ 2,  2, 19, ...,  0,  0,  0],\n",
              "       [ 2,  2, 19, ...,  0,  0,  0],\n",
              "       [ 2,  2,  0, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 2,  2,  0, ...,  0,  0,  0],\n",
              "       [ 2,  2,  0, ...,  0,  0,  0],\n",
              "       [ 2,  2,  0, ...,  0,  0,  0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_inp_size = len(tokenizer.word_index)+1\n",
        "vocab_tar_size = len(tags)+1\n",
        "max_length_input = example_X_batch.shape[1]\n",
        "max_length_output = example_Y_batch.shape[1]\n",
        "\n",
        "embedding_dim = 64\n",
        "units = 64\n",
        "\n",
        "BUFFER_SIZE = 32000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "q595S90E4ue1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.gru_layer = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, h = self.gru_layer(x, initial_state = hidden)\n",
        "        return output, h\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        # initial hidden state\n",
        "        return [tf.zeros((self.batch_sz, self.enc_units))] "
      ],
      "metadata": {
        "id": "zB91ibWB4KAg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test Encoder Stack\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "\n",
        "# sample input\n",
        "sample_output, sample_h = encoder(example_X_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tRJd3Rf7NpR",
        "outputId": "3a7c423b-fdb5-4b6e-b0d3-82e7a8dee352"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 930, 64)\n",
            "Encoder h vecotr shape: (batch size, units) (64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Test attn"
      ],
      "metadata": {
        "id": "y6zzPH1ScpaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "max_time = 7\n",
        "hidden_size = 32\n",
        "embedding_size = 48\n",
        "input_vocab_size = 128\n",
        "output_vocab_size = 2\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(input_vocab_size, embedding_size)\n",
        "sampler = tfa.seq2seq.TrainingSampler()\n",
        "output_layer = tf.keras.layers.Dense(output_vocab_size)\n",
        "\n",
        "# mock data\n",
        "input_ids = tf.random.uniform(\n",
        "    [batch_size, max_time], maxval=input_vocab_size, dtype=tf.int64)\n",
        "\n",
        "input_lengths = [5,6,2,7]\n",
        "mask = [\n",
        "        [True if i<valid_len else False for i in range(max_time) ] \n",
        "        for valid_len in input_lengths\n",
        "]\n",
        "\n",
        "input_tensors = embedding_layer(input_ids)\n",
        "\n",
        "## Encoder \n",
        "encoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences = True, return_state = True)\n",
        "enc_sequences, *state = encoder_lstm(input_tensors)"
      ],
      "metadata": {
        "id": "iQ6plc-vcr-5"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLiwHVfuctPE",
        "outputId": "c0d3a667-c730-43ff-8108-a370a5f342b7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 7, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nrCNNQjeGXz",
        "outputId": "da08537e-dfe1-488c-c50d-5affccd68651"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 7, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb3NmeRGf0Zc",
        "outputId": "fdfe7e70-e471-40ae-d8b7-affafb00cf38"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 7, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = enc_sequences\n",
        "\n",
        "# Attentioned RNN decoder\n",
        "\n",
        "attention = tfa.seq2seq.LuongAttention(\n",
        "        units  = 2, \n",
        "        memory = query,  # The memory to query; RNN encoder output sequence.\n",
        "        memory_sequence_length = input_lengths  # valid length mask\n",
        "    )\n",
        "\n",
        "decoder_cell = tfa.seq2seq.AttentionWrapper(\n",
        "    tf.keras.layers.LSTMCell(hidden_size),\n",
        "    attention_mechanism = attention\n",
        ")\n",
        "\n",
        "# decoder\n",
        "decoder = tfa.seq2seq.BasicDecoder(decoder_cell, sampler)\n",
        "\n",
        "\n",
        "initial_state = decoder_cell.get_initial_state(input_tensors)\n",
        "\n",
        "output, state, lengths = decoder(\n",
        "    input_tensors, initial_state=initial_state,\n",
        "    sequence_length = input_lengths)\n",
        "\n",
        "logits = output.rnn_output\n",
        "logits.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BzwWuTKMXbFK",
        "outputId": "4948b67a-5b44-4ec1-f4c6-d508197d6d09"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-2a98c87358b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m output, state, lengths = decoder(\n\u001b[1;32m     23\u001b[0m     \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     sequence_length = input_lengths)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/decoder.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, initial_state, training, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mdecoder_init_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mdecoder_init_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         )\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/typeguard/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CallMemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_localns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0mcheck_argument_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0mcheck_return_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/decoder.py\u001b[0m in \u001b[0;36mdynamic_decode\u001b[0;34m(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, training, scope, enable_tflite_convertible, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         )\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/decoder.py\u001b[0m in \u001b[0;36mbody\u001b[0;34m(time, outputs_ta, state, inputs, finished, sequence_lengths)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \"\"\"\n\u001b[1;32m    427\u001b[0m             (next_outputs, decoder_state, next_inputs, decoder_finished) = decoder.step(\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m             )\n\u001b[1;32m    430\u001b[0m             \u001b[0mdecoder_state_sequence_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/basic_decoder.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, time, inputs, state, training)\u001b[0m\n\u001b[1;32m    132\u001b[0m           \u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mcell_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/attention_wrapper.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state, **kwargs)\u001b[0m\n\u001b[1;32m   2029\u001b[0m                 \u001b[0mcell_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m                 \u001b[0mprevious_attention_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attention_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attention_layers\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m             )\n\u001b[1;32m   2033\u001b[0m             alignment_history = (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/attention_wrapper.py\u001b[0m in \u001b[0;36m_compute_attention\u001b[0;34m(attention_mechanism, cell_output, attention_state, attention_layer)\u001b[0m\n\u001b[1;32m   1547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mechanism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_BaseAttentionMechanism\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         alignments, next_attention_state = attention_mechanism(\n\u001b[0;32m-> 1549\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mcell_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1550\u001b[0m         )\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/attention_wrapper.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/attention_wrapper.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, setup_memory, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_sequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/attention_wrapper.py\u001b[0m in \u001b[0;36m_calculate_attention\u001b[0;34m(self, query, state)\u001b[0m\n\u001b[1;32m    598\u001b[0m           \u001b[0mnext_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0malignments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \"\"\"\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_luong_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m         \u001b[0malignments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malignments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/seq2seq/attention_wrapper.py\u001b[0m in \u001b[0;36m_luong_score\u001b[0;34m(query, keys, scale)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;34m\"Query (%s) has units: %s.  Keys (%s) have units: %s.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;34m\"Perhaps you need to set num_units to the keys' dimension (%s)?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         )\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"LuongAttention\" (type LuongAttention).\n\nIncompatible or unknown inner dimensions between query and keys. Query (tf.Tensor(\n[[-5.97432535e-03 -7.08352495e-03 -8.55009165e-03 -8.48071836e-03\n  -4.72342782e-03  1.09123671e-03 -4.40542400e-03 -6.75825169e-03\n   3.39711993e-03  1.80605613e-03 -3.47218913e-04 -1.44641325e-02\n   5.97018865e-04 -2.74846028e-03 -7.94825330e-03 -8.72348319e-04\n  -3.40843434e-03  9.75135807e-03  4.97381762e-03  6.89403794e-04\n   5.71741955e-03 -5.14394697e-03  2.99701816e-04  2.69727060e-03\n   6.45082956e-03  6.51723426e-03 -3.41626559e-03  1.17869268e-03\n  -1.55669451e-03  3.18506919e-03  1.29674198e-02  1.62970321e-03]\n [-8.50535184e-03 -2.42804817e-04 -5.64447418e-03  5.79977967e-03\n   3.01183230e-04  2.47726357e-03 -5.59374597e-03  1.54087821e-03\n  -3.28061543e-03  1.64543383e-03  6.24654524e-04 -9.05900355e-03\n  -4.91714757e-03  5.31691127e-03 -2.47099577e-03  6.14232011e-03\n   1.69528765e-03 -6.02824846e-03  7.41401396e-04  5.40547771e-03\n   4.76134289e-03  3.03273555e-03 -4.46428172e-03  5.55052795e-03\n   1.14183836e-02 -2.52848375e-04 -1.08967687e-03 -5.94605692e-04\n  -1.31430523e-03 -2.62646028e-03  4.31672670e-03  3.25624156e-03]\n [-4.74654185e-03  9.14948899e-03  6.55270042e-03 -8.04624520e-04\n   6.59761718e-03 -1.35877845e-03  1.27101026e-03  3.47566814e-03\n   3.83990118e-03  6.30861800e-03 -5.93659934e-04  6.69559697e-03\n  -1.51596102e-03 -3.54189728e-03 -5.89624513e-04  6.28925860e-03\n  -1.37473568e-02 -9.82980616e-03 -1.96678285e-03  3.06492602e-03\n  -8.74674122e-04  5.63394930e-03 -6.07183203e-03 -4.85965284e-03\n   4.42933571e-03  4.84138867e-03 -8.49776249e-03  4.78386739e-03\n   3.29900905e-03 -2.98641296e-03 -1.01161026e-03 -2.44444935e-03]\n [-6.97388267e-03 -2.34720251e-03 -3.85379861e-03 -3.61584988e-03\n  -3.58449365e-03 -8.97758268e-03 -5.38715534e-03 -9.65130574e-04\n   1.30147778e-03 -2.92957458e-03 -9.68193542e-03 -7.31065054e-04\n   4.00228472e-03 -3.65131977e-03 -9.86372121e-03  1.53822557e-03\n  -4.21741512e-03 -3.67236068e-03  8.95562954e-03 -8.23595561e-03\n  -3.79150547e-03  1.38680637e-03  2.92528166e-05 -1.20538427e-03\n  -8.10561176e-07  1.42265263e-03  1.17638037e-02 -2.47518532e-03\n  -7.02099176e-03 -1.02140219e-03  3.05825286e-03  9.44513176e-03]], shape=(4, 32), dtype=float32)) has units: 32.  Keys (tf.Tensor(\n[[[-7.7905743e-03  1.9229068e-03]\n  [-1.7219324e-02  4.2615710e-03]\n  [-5.1000603e-03  1.9704248e-04]\n  [-1.4013765e-02  7.4739596e-03]\n  [-1.1042741e-02  9.8311026e-03]\n  [ 0.0000000e+00  0.0000000e+00]\n  [ 0.0000000e+00  0.0000000e+00]]\n\n [[ 6.4025982e-05 -6.6597611e-03]\n  [-7.3582917e-03 -1.0353958e-02]\n  [-8.2260063e-03 -1.8426918e-03]\n  [ 2.6420807e-03 -8.7390514e-03]\n  [ 2.4105471e-03 -1.0882895e-02]\n  [ 5.7276944e-03 -1.9342929e-02]\n  [ 0.0000000e+00  0.0000000e+00]]\n\n [[ 5.5617527e-03 -7.0133288e-03]\n  [ 5.2420574e-04 -4.2982865e-03]\n  [ 0.0000000e+00  0.0000000e+00]\n  [ 0.0000000e+00  0.0000000e+00]\n  [ 0.0000000e+00  0.0000000e+00]\n  [ 0.0000000e+00  0.0000000e+00]\n  [ 0.0000000e+00  0.0000000e+00]]\n\n [[-3.9145583e-04 -3.2818697e-03]\n  [-4.2368281e-03 -8.3515067e-03]\n  [-5.4463660e-03 -1.0267988e-02]\n  [-1.8546179e-02 -1.6336141e-02]\n  [-1.8016489e-02 -1.7049789e-02]\n  [-1.7416837e-02 -1.6481195e-02]\n  [-1.4258040e-02 -1.3036869e-02]]], shape=(4, 7, 2), dtype=float32)) have units: 2.  Perhaps you need to set num_units to the keys' dimension (2)?\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(4, 32), dtype=float32)', 'tf.Tensor(shape=(4, 7), dtype=float32)', 'tf.Tensor(shape=(4, 7, 32), dtype=float32)']\n  • mask=None\n  • setup_memory=False\n  • kwargs={'training': 'None'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozzZmTVkmsHr",
        "outputId": "5e80fe0c-4c4e-4ed9-a3b0-b8144d37fe17"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7, 48), dtype=float32, numpy=\n",
              "array([[[-0.00920322,  0.03080458, -0.04706008, ...,  0.02843005,\n",
              "          0.04914875, -0.02121426],\n",
              "        [ 0.018262  ,  0.04097637,  0.02961249, ..., -0.00262671,\n",
              "          0.03874794, -0.01295703],\n",
              "        [ 0.01946372,  0.03727869, -0.00974437, ...,  0.00460287,\n",
              "         -0.02529764,  0.02750375],\n",
              "        ...,\n",
              "        [-0.04680122, -0.01320962, -0.00540948, ...,  0.00557275,\n",
              "         -0.02082304, -0.0431443 ],\n",
              "        [-0.01912578,  0.03242162,  0.00185368, ...,  0.01762482,\n",
              "          0.00276135,  0.01354733],\n",
              "        [-0.02686486, -0.03371592, -0.03499549, ..., -0.02348628,\n",
              "          0.00045349, -0.00762911]],\n",
              "\n",
              "       [[ 0.00581073,  0.03883186, -0.01562633, ...,  0.0219874 ,\n",
              "          0.02373847, -0.03124186],\n",
              "        [ 0.01369936,  0.00148897,  0.04216638, ...,  0.00099827,\n",
              "         -0.02962055,  0.02090689],\n",
              "        [-0.01728929, -0.04492406, -0.03196266, ..., -0.01838011,\n",
              "          0.03195058, -0.02541676],\n",
              "        ...,\n",
              "        [-0.00386453, -0.00404745,  0.04547555, ...,  0.01977787,\n",
              "          0.01746321,  0.02362168],\n",
              "        [ 0.04702154, -0.03339015,  0.02380314, ..., -0.04136323,\n",
              "          0.03099174,  0.01811473],\n",
              "        [ 0.02131828, -0.01086745,  0.02179923, ..., -0.01295906,\n",
              "         -0.02057368,  0.04078558]],\n",
              "\n",
              "       [[ 0.00368197, -0.02310971, -0.03533931, ...,  0.03432992,\n",
              "         -0.03603954, -0.0408948 ],\n",
              "        [ 0.02981851,  0.00403462,  0.03403753, ..., -0.01480595,\n",
              "          0.01137856,  0.00810385],\n",
              "        [ 0.03850427, -0.00575684,  0.04356614, ...,  0.0222589 ,\n",
              "          0.02452651, -0.03339329],\n",
              "        ...,\n",
              "        [ 0.02819497, -0.02702403,  0.03729242, ..., -0.02147165,\n",
              "         -0.02897172, -0.00221493],\n",
              "        [ 0.024548  ,  0.04383886, -0.02230741, ...,  0.02361367,\n",
              "         -0.00404393,  0.04087723],\n",
              "        [ 0.03792847, -0.01872469,  0.03029234, ...,  0.03908754,\n",
              "          0.0301151 , -0.00404781]],\n",
              "\n",
              "       [[-0.00386453, -0.00404745,  0.04547555, ...,  0.01977787,\n",
              "          0.01746321,  0.02362168],\n",
              "        [ 0.0409095 , -0.04725429, -0.014011  , ...,  0.00796503,\n",
              "         -0.00434721, -0.04539058],\n",
              "        [ 0.04531796,  0.02572903, -0.00466698, ..., -0.01225997,\n",
              "         -0.00191603,  0.04768188],\n",
              "        ...,\n",
              "        [-0.04640659,  0.00567783, -0.00477487, ...,  0.01780141,\n",
              "         -0.03516633, -0.0036355 ],\n",
              "        [ 0.02848672, -0.01011146, -0.04766991, ..., -0.02340133,\n",
              "          0.04405368,  0.04990971],\n",
              "        [-0.01324088, -0.04096831,  0.00087317, ..., -0.0378131 ,\n",
              "          0.03972168, -0.00948238]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZTKGOXwkcgl",
        "outputId": "4ed731d6-4ddf-4723-ef33-16ff3621a61b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7, 32), dtype=float32, numpy=\n",
              "array([[[-9.57207987e-04,  9.51110851e-03,  8.91561620e-03,\n",
              "          3.22170602e-03,  1.56557432e-03, -2.11643800e-03,\n",
              "         -1.78371993e-04, -7.77929462e-03,  3.15717026e-03,\n",
              "          8.51548510e-04, -1.25742611e-03, -2.43971660e-03,\n",
              "         -5.65995276e-03, -6.57207472e-03, -1.55241159e-03,\n",
              "         -7.27468170e-03, -1.16107017e-02, -6.42238185e-03,\n",
              "          1.49193616e-03, -6.37725601e-03, -6.42789435e-03,\n",
              "          1.05227418e-02, -5.14355069e-03, -1.87336598e-04,\n",
              "          3.28373699e-03, -5.50639071e-03,  2.34349677e-03,\n",
              "          6.81360159e-03, -9.30562324e-04, -3.50032980e-03,\n",
              "          2.08958238e-03, -3.59851256e-04],\n",
              "        [ 1.04960217e-03,  8.68157018e-03,  1.52512984e-02,\n",
              "          1.31361675e-03,  1.64882489e-03, -1.08301621e-02,\n",
              "          1.79255323e-03, -3.95470671e-03,  5.39222173e-03,\n",
              "         -3.71568021e-03, -6.54590828e-03, -4.98428103e-03,\n",
              "         -1.77675970e-02, -8.80812109e-03, -2.74751009e-03,\n",
              "         -9.82597284e-03, -8.78477935e-03, -2.26341595e-04,\n",
              "          3.53308185e-03, -1.47015937e-02, -1.15190167e-02,\n",
              "          1.43155502e-02, -1.01817697e-02, -5.36031649e-03,\n",
              "          7.37657817e-03, -9.44888033e-03, -4.01031179e-03,\n",
              "          5.93827013e-03,  1.34405436e-03, -4.97414591e-03,\n",
              "          5.40159270e-03, -6.53749751e-03],\n",
              "        [ 6.75333664e-03,  9.51198954e-03, -1.28901168e-03,\n",
              "          9.58544388e-03, -2.93547940e-03, -6.26046909e-03,\n",
              "         -3.83391371e-03, -7.01878732e-03, -2.20322004e-03,\n",
              "          7.12574134e-03, -5.93518466e-03, -7.50620849e-03,\n",
              "         -8.27983767e-03, -7.91772269e-03,  8.58271669e-04,\n",
              "         -9.79758147e-03,  1.52353616e-03,  2.74500158e-03,\n",
              "         -3.11811757e-03, -1.05641149e-02, -5.23810880e-03,\n",
              "          7.74119934e-03, -8.88782088e-03,  2.67557846e-03,\n",
              "          6.65525580e-03, -6.39468757e-03, -3.54276435e-03,\n",
              "          7.90391769e-03,  1.52685994e-03, -3.80751537e-03,\n",
              "          7.64531037e-03,  8.67851486e-04],\n",
              "        [ 7.43241794e-03,  1.00095058e-02, -3.17570427e-03,\n",
              "          5.79500431e-03, -3.36261961e-04, -7.78182363e-03,\n",
              "         -4.68979683e-03, -7.42906053e-03,  3.63279972e-03,\n",
              "          5.76767046e-03,  4.07588173e-04, -4.68241889e-03,\n",
              "         -8.98436271e-03, -5.90054668e-04,  3.99473793e-04,\n",
              "         -2.68170703e-03,  2.48331227e-03,  1.18824737e-02,\n",
              "          4.30946966e-04, -1.74841715e-03, -7.20182713e-03,\n",
              "          6.93038863e-04, -7.73355411e-03, -1.64595127e-04,\n",
              "          9.39715467e-03, -7.00972509e-03,  1.68352132e-03,\n",
              "          5.37305279e-03,  6.28962240e-04,  2.79508950e-03,\n",
              "          1.55704177e-03, -1.43710570e-03],\n",
              "        [ 1.10139921e-02,  1.25334235e-02, -5.42462803e-03,\n",
              "          7.09018344e-03, -4.31080395e-03,  1.23618834e-03,\n",
              "         -7.08407373e-04, -8.63471907e-03,  1.02945045e-02,\n",
              "          8.36259127e-03,  7.86662195e-03, -7.74677563e-03,\n",
              "         -1.25570334e-02, -1.38663454e-03, -8.22426938e-03,\n",
              "          5.80937412e-05,  8.59726407e-03,  4.40815231e-03,\n",
              "          4.82029188e-03,  4.26966976e-03, -3.46531114e-03,\n",
              "         -5.17166080e-03, -1.01132700e-02,  9.05084983e-03,\n",
              "          5.51575376e-03, -8.28715973e-03,  8.24963581e-03,\n",
              "          3.06496792e-03, -2.85012904e-03,  6.08722540e-03,\n",
              "         -6.27076393e-03,  7.76877347e-03],\n",
              "        [ 1.83976954e-03,  1.48362853e-02,  5.55849029e-03,\n",
              "          7.65403314e-03, -7.56222568e-03,  1.96180918e-04,\n",
              "         -2.72092549e-03, -1.35863796e-02,  5.73384576e-03,\n",
              "          4.72980272e-03, -9.21143917e-04, -7.95780495e-03,\n",
              "         -1.31851928e-02, -6.37806812e-03, -1.65037923e-02,\n",
              "          4.86708060e-03,  1.39779248e-03,  2.14517536e-03,\n",
              "          1.65473148e-02, -1.23275316e-03, -8.08763690e-03,\n",
              "         -1.36146974e-03, -1.17742736e-02,  7.48904515e-03,\n",
              "          9.00123036e-04, -8.47665500e-03,  5.67135634e-03,\n",
              "          5.88507345e-03, -2.09623645e-03,  2.66995886e-03,\n",
              "         -1.41555432e-03,  1.15945842e-03],\n",
              "        [ 1.75210426e-03,  1.70713589e-02, -1.04028289e-03,\n",
              "          1.27769802e-02, -2.46720295e-03,  1.37010228e-03,\n",
              "         -7.92946201e-03, -7.61101348e-03, -2.47179298e-03,\n",
              "         -6.53002877e-03,  1.56818668e-03, -1.23223495e-02,\n",
              "         -1.50735686e-02, -8.24145693e-03, -1.52543690e-02,\n",
              "          3.85957886e-03,  5.79565065e-03, -3.14539997e-03,\n",
              "          1.81233566e-02,  3.74341337e-03, -2.10241205e-03,\n",
              "         -8.88026133e-03, -8.55321065e-03,  9.13361832e-03,\n",
              "          6.84487959e-03, -6.18107151e-03, -3.63773579e-04,\n",
              "         -2.53811223e-03,  9.55609663e-04,  9.92465415e-04,\n",
              "         -4.99633548e-04,  8.40106048e-04]],\n",
              "\n",
              "       [[-8.72386713e-03,  3.92929791e-03,  2.22830335e-03,\n",
              "         -5.03562298e-03,  7.79578090e-03, -5.67137869e-03,\n",
              "          9.03993379e-03,  6.47599343e-03,  6.75887393e-04,\n",
              "          6.10759947e-03, -9.65257233e-04,  6.33595511e-04,\n",
              "          3.25751444e-03,  9.21123428e-04,  4.59179003e-03,\n",
              "         -2.94946134e-03, -5.97118493e-03, -4.67795553e-03,\n",
              "         -3.94257996e-03, -3.33787408e-03,  3.12204659e-03,\n",
              "         -7.16632791e-03,  5.37565257e-03, -5.87906875e-03,\n",
              "          1.74623181e-03,  5.20471542e-04, -1.24869193e-03,\n",
              "         -4.17553494e-03, -8.74130288e-04,  1.30642136e-03,\n",
              "          3.76240141e-03,  4.34953393e-03],\n",
              "        [-6.93933573e-03,  1.82076788e-03, -8.05132498e-04,\n",
              "         -9.34034120e-03,  1.56389433e-03, -1.27035929e-02,\n",
              "          9.90310125e-03,  7.77162844e-03,  3.55966086e-03,\n",
              "          4.30217246e-03,  3.22819658e-04,  5.63351484e-03,\n",
              "          5.74789057e-03,  2.34533334e-03, -1.76013738e-03,\n",
              "         -7.45449821e-03, -2.88062193e-03, -2.08941125e-03,\n",
              "         -3.96213913e-03, -4.57568676e-04,  4.99885902e-03,\n",
              "         -7.08848331e-03,  1.23314401e-02, -5.05287480e-03,\n",
              "          2.47816462e-03, -2.34520482e-03, -1.76982445e-04,\n",
              "         -8.31649546e-03, -7.27863424e-03,  4.97106882e-03,\n",
              "         -2.10130168e-03, -9.48054541e-04],\n",
              "        [-2.99549964e-03,  8.30127392e-03, -3.51075642e-03,\n",
              "         -1.20447502e-02, -1.35048067e-05, -1.26066580e-02,\n",
              "          7.21627427e-03,  7.15035480e-04,  1.02336314e-02,\n",
              "         -3.21573881e-03,  1.36125293e-02, -6.53061876e-03,\n",
              "          5.50882332e-03,  2.81554204e-03, -8.28927755e-03,\n",
              "         -6.76956261e-03, -2.38610408e-03, -1.02158764e-03,\n",
              "         -3.84509866e-03, -9.56660695e-03,  1.04352143e-02,\n",
              "         -2.61487963e-04,  4.42365010e-04, -8.86130333e-03,\n",
              "          4.27421073e-05, -8.83610733e-03,  5.18895919e-03,\n",
              "         -1.12265022e-02, -2.71760067e-03, -4.83657606e-03,\n",
              "         -9.40753889e-05, -1.11617409e-02],\n",
              "        [-2.75929505e-03,  1.94159197e-03,  4.88086045e-03,\n",
              "         -2.88658380e-03,  1.79737911e-03, -1.01681193e-02,\n",
              "          9.50805005e-03, -8.76920240e-04,  5.90975862e-03,\n",
              "         -1.33593306e-02,  1.13470815e-02, -7.15647824e-03,\n",
              "          4.03854530e-03, -1.74675614e-03, -8.14350601e-03,\n",
              "         -5.21445274e-03, -6.28343970e-03,  1.82873558e-03,\n",
              "         -3.20493872e-03, -7.63320178e-03,  2.40438003e-02,\n",
              "          1.00402092e-03,  5.20310085e-03, -7.37659354e-03,\n",
              "         -8.34183069e-04, -1.47604430e-02,  2.26421840e-03,\n",
              "         -1.24414722e-02, -2.26374972e-03, -1.32948700e-02,\n",
              "          5.70432981e-04, -1.10234031e-02],\n",
              "        [-1.19080569e-03,  2.46772752e-03,  8.21551494e-03,\n",
              "         -5.04349545e-03,  4.39317105e-03, -9.54729039e-03,\n",
              "          1.73143682e-03, -5.87933138e-03,  1.48647197e-03,\n",
              "         -1.05685024e-02,  9.94246081e-03, -7.68075138e-03,\n",
              "         -1.96841150e-03, -9.80779901e-03, -3.82888457e-03,\n",
              "         -6.79896399e-03, -1.35501020e-03,  1.89535160e-04,\n",
              "         -4.91789682e-03, -1.09558208e-02,  9.69989877e-03,\n",
              "          3.79480724e-03,  5.40624419e-03, -4.55327099e-03,\n",
              "          1.27980178e-02, -1.75947845e-02, -5.21402899e-03,\n",
              "         -9.58672725e-03,  1.00979619e-02, -2.30864976e-02,\n",
              "         -1.12200696e-02, -1.13106500e-02],\n",
              "        [-1.06407907e-02,  3.84315825e-03,  2.34599318e-03,\n",
              "          9.14640957e-04,  9.96561162e-03, -1.09425606e-02,\n",
              "         -2.30412069e-03, -8.21456313e-03, -3.82280676e-03,\n",
              "         -7.69452564e-03,  9.99876298e-03, -1.43011175e-02,\n",
              "         -2.71299905e-05, -1.26349637e-02, -9.17506125e-03,\n",
              "         -6.73212158e-03, -3.71427182e-03, -5.04094129e-03,\n",
              "          6.99265162e-03, -1.01896441e-02,  7.36595364e-03,\n",
              "          3.80651001e-03,  7.89344311e-03, -1.16196796e-02,\n",
              "          1.26200980e-02, -1.49109401e-02, -5.65560907e-03,\n",
              "         -9.59368609e-03,  6.96119992e-03, -2.70356443e-02,\n",
              "         -1.27303191e-02, -1.28853507e-02],\n",
              "        [-3.87577619e-03,  1.08285965e-02, -4.21680091e-03,\n",
              "         -2.43496965e-03,  4.58387006e-03, -2.34078872e-03,\n",
              "         -1.24386966e-03, -1.24100782e-02, -5.23568736e-03,\n",
              "         -5.75926481e-03,  1.94071010e-02, -1.06522646e-02,\n",
              "          2.25710892e-03, -3.07679921e-03, -8.59102886e-03,\n",
              "         -4.58609592e-03, -9.12346353e-04,  6.57845638e-04,\n",
              "          9.07338131e-03, -2.35948968e-03,  4.46447777e-03,\n",
              "         -3.29250121e-04,  5.36420895e-03, -7.55769899e-03,\n",
              "          4.69467277e-03, -1.40845599e-02, -1.10017285e-02,\n",
              "         -5.98379876e-03,  7.44259637e-03, -1.60896797e-02,\n",
              "         -9.19517223e-03, -7.33098062e-03]],\n",
              "\n",
              "       [[ 3.23968800e-03,  1.90439308e-03,  4.13405383e-03,\n",
              "         -2.55859876e-03, -5.13271312e-04,  2.37895921e-03,\n",
              "         -2.65568029e-03,  4.32743225e-03, -1.68863079e-03,\n",
              "         -3.84172751e-03,  3.11754644e-03, -3.38120246e-03,\n",
              "          2.56738072e-04, -2.35309568e-03,  1.82185345e-03,\n",
              "          3.46272951e-04, -5.85419824e-03, -5.87418908e-03,\n",
              "          4.49216226e-03,  6.02420885e-03,  1.06589748e-02,\n",
              "          4.78006294e-03,  9.23760381e-05,  2.03173375e-03,\n",
              "          2.32639792e-03, -6.68760482e-03,  9.21122357e-03,\n",
              "         -4.58323071e-03, -3.77091835e-03, -2.20648758e-03,\n",
              "         -1.05882045e-02,  5.42552629e-03],\n",
              "        [ 2.81755091e-03,  5.41696884e-03,  3.16391164e-03,\n",
              "         -4.35903715e-03, -3.23453755e-03,  5.42300940e-03,\n",
              "          1.97500325e-04,  4.91813477e-03, -4.14825371e-03,\n",
              "         -3.84924072e-03, -2.75068451e-03, -1.10798860e-02,\n",
              "          1.75959407e-03, -6.33262377e-03, -5.37083135e-04,\n",
              "         -4.45940904e-03, -2.02805689e-03, -1.24789188e-02,\n",
              "          3.48745123e-03,  6.47966843e-03, -3.08549992e-04,\n",
              "          3.15223821e-03, -4.52378811e-03,  2.27995659e-03,\n",
              "         -2.65193055e-03, -4.30049840e-04, -2.05862289e-03,\n",
              "         -1.20900094e-03, -4.25345264e-03,  5.42202545e-03,\n",
              "         -6.35846006e-03,  1.11460015e-02],\n",
              "        [ 2.16744863e-03, -1.78944890e-03,  3.22390907e-03,\n",
              "         -2.51831207e-03, -4.84703016e-03, -5.80511708e-03,\n",
              "         -1.08024757e-02,  5.75376023e-03, -3.74731282e-03,\n",
              "         -3.08011263e-03, -5.98564791e-03, -9.77372844e-03,\n",
              "          6.35835994e-03, -4.79969848e-03,  8.66074953e-03,\n",
              "         -4.62175207e-03, -2.33821012e-03, -1.18342880e-02,\n",
              "          3.95287527e-03,  1.36771647e-03,  5.41467126e-03,\n",
              "          3.64429713e-03, -3.96042457e-03, -4.79334034e-03,\n",
              "          6.07137568e-03, -1.19156884e-02,  6.66178006e-04,\n",
              "         -3.88857163e-03, -7.67629535e-04, -4.80750808e-03,\n",
              "         -4.39469656e-03,  5.56153525e-03],\n",
              "        [ 5.05694002e-03, -2.01644213e-03,  5.81886619e-03,\n",
              "         -4.69910726e-03,  4.80182562e-03, -1.13082947e-02,\n",
              "         -8.59175343e-04,  1.03825731e-02, -7.39372568e-03,\n",
              "          4.42931801e-03,  3.71446181e-03,  5.49853985e-06,\n",
              "          9.95462108e-03,  2.87985895e-03,  4.39392682e-03,\n",
              "         -1.84268355e-02,  4.14263830e-03, -2.92586675e-03,\n",
              "         -3.57151893e-03, -9.37274774e-04, -4.20853001e-04,\n",
              "          8.76324717e-03, -4.43689153e-03, -9.50349960e-03,\n",
              "          7.89252669e-03, -1.57176759e-02,  5.17813023e-03,\n",
              "          6.43507391e-03, -4.31331620e-03, -2.34195311e-03,\n",
              "         -1.54607254e-03,  1.92827880e-02],\n",
              "        [ 1.05366921e-02, -3.77902389e-03,  3.94880306e-03,\n",
              "         -1.01174144e-02, -1.66915520e-03, -1.60634629e-02,\n",
              "          6.91590179e-03,  7.43906107e-03, -4.02305229e-03,\n",
              "          6.50514290e-03,  3.03686503e-03,  9.11760144e-03,\n",
              "          6.60889735e-03,  1.07988827e-02,  6.19945675e-03,\n",
              "         -1.05410693e-02,  1.07587362e-02,  3.82393389e-03,\n",
              "          2.15883367e-03,  9.12937429e-03,  2.22746120e-03,\n",
              "          5.95756527e-03, -1.93316338e-03, -1.47622498e-02,\n",
              "          9.24532022e-03, -1.39326807e-02,  1.17286826e-02,\n",
              "          7.96470884e-03, -6.64258422e-03,  9.19733022e-04,\n",
              "         -1.42325405e-02,  1.87327266e-02],\n",
              "        [ 9.98766068e-03, -7.15343235e-03,  6.64656702e-03,\n",
              "         -1.09200720e-02, -8.57448112e-03, -6.05420442e-03,\n",
              "          6.30556513e-03, -1.20873249e-03, -7.44447950e-03,\n",
              "          9.45053715e-03, -7.58029567e-03,  7.59541243e-03,\n",
              "          4.75801947e-03,  5.14921034e-03,  5.48320403e-03,\n",
              "         -1.61454570e-03,  9.11651179e-03, -1.44471903e-03,\n",
              "          4.07974655e-03,  1.29527096e-02, -5.62748639e-03,\n",
              "          5.07136865e-04, -4.07819683e-03, -6.99214404e-03,\n",
              "          1.03684235e-02, -1.56467091e-02,  7.87431654e-03,\n",
              "          7.33624306e-03, -8.51670466e-03,  1.14434995e-02,\n",
              "         -1.82938054e-02,  1.91877075e-02],\n",
              "        [ 1.16693294e-02, -1.03535205e-02,  6.94153178e-03,\n",
              "         -1.17290085e-02, -1.38364965e-03, -4.20830771e-03,\n",
              "          4.90195071e-03, -1.00940317e-02, -7.83011783e-03,\n",
              "          9.00493935e-03, -7.77249224e-03,  3.19516577e-04,\n",
              "          7.75344344e-03,  4.47351998e-03, -3.49517865e-03,\n",
              "          3.05579300e-03,  3.49147432e-03, -7.14108907e-03,\n",
              "          7.15573831e-03,  1.42879095e-02, -6.66730059e-03,\n",
              "         -4.18055197e-03, -3.61714419e-03, -5.00338909e-04,\n",
              "          4.29728971e-04, -1.57834254e-02,  9.34355147e-03,\n",
              "          1.02664456e-02, -1.02633974e-02,  1.84273291e-02,\n",
              "         -1.10235214e-02,  1.24457153e-02]],\n",
              "\n",
              "       [[ 2.66112364e-03,  1.09659496e-03,  6.97395066e-03,\n",
              "         -1.95760466e-03,  3.81987379e-03, -3.40283941e-03,\n",
              "         -5.65829873e-03, -5.44646569e-03, -2.40005739e-03,\n",
              "         -2.45502964e-03,  2.93299439e-04, -2.55716383e-03,\n",
              "         -5.83283138e-03, -8.32550786e-03,  2.45430018e-03,\n",
              "         -3.05453688e-03,  2.06271955e-03, -1.90535688e-03,\n",
              "         -2.35264935e-03, -5.28401230e-03, -8.24755523e-03,\n",
              "          4.25380701e-03,  2.58172280e-03,  2.26357937e-04,\n",
              "          1.40936589e-02, -5.28731523e-03, -5.85871702e-03,\n",
              "         -8.60137516e-04,  1.02734501e-02, -1.11966832e-02,\n",
              "         -9.61842015e-03, -2.52034864e-03],\n",
              "        [-5.52461576e-03, -3.69976740e-03,  7.68943224e-03,\n",
              "         -2.00569909e-02,  1.78914778e-02, -7.45219830e-03,\n",
              "         -8.86080042e-03,  5.03731286e-03, -1.22751500e-02,\n",
              "         -5.97550534e-03, -2.96073826e-03, -2.52171140e-03,\n",
              "          1.01393752e-03, -4.15520929e-03,  3.98853514e-03,\n",
              "         -3.00237152e-04, -7.22487271e-03, -4.42882068e-03,\n",
              "          4.63277008e-03, -5.80169447e-03, -2.76601547e-03,\n",
              "         -1.09881139e-03,  3.11929826e-03,  9.97364288e-04,\n",
              "          7.79716857e-03, -7.08318967e-03, -3.91366193e-03,\n",
              "         -8.97175074e-03,  4.27648891e-03, -3.57269682e-03,\n",
              "         -3.01019195e-03, -8.11882876e-03],\n",
              "        [-5.22770733e-03, -6.47447864e-03,  1.44269355e-02,\n",
              "         -1.81818362e-02,  4.18609194e-03, -9.19934269e-03,\n",
              "         -2.06165686e-02,  9.24168527e-03, -9.84455179e-03,\n",
              "         -8.51116888e-03, -9.30129725e-04, -6.56243972e-03,\n",
              "         -4.43817303e-03, -1.75546389e-03,  2.18607695e-03,\n",
              "          8.64724722e-03,  9.23158834e-04,  3.06983548e-03,\n",
              "          2.48319004e-03, -4.12601326e-03, -5.94123220e-03,\n",
              "          1.85556244e-03,  3.50404461e-03, -8.08150333e-04,\n",
              "          1.10352533e-02, -1.20588848e-02, -8.77031311e-03,\n",
              "         -8.04735534e-03,  4.69324924e-03, -9.32173245e-03,\n",
              "         -4.56783315e-03, -9.01614036e-03],\n",
              "        [-7.40574207e-04, -3.00928578e-03, -1.14805123e-03,\n",
              "         -9.75613669e-03, -7.96578079e-03, -6.30338397e-03,\n",
              "         -2.19459143e-02,  5.40799042e-03, -6.04829844e-03,\n",
              "         -1.85508828e-03, -3.38501693e-03, -4.90322709e-03,\n",
              "         -9.97879077e-03, -4.05695243e-03,  6.24255184e-03,\n",
              "         -6.77059079e-03, -7.77148525e-04, -6.52102381e-03,\n",
              "          6.62848493e-03, -2.51292554e-03, -9.23690572e-03,\n",
              "          2.96023587e-04,  5.52941021e-03,  3.60110146e-03,\n",
              "          6.77164551e-03, -1.49373757e-02, -1.56760979e-02,\n",
              "         -5.59303304e-03,  3.62985744e-03, -5.79357287e-03,\n",
              "         -6.79182215e-03, -2.73311604e-03],\n",
              "        [-1.22383994e-03, -1.78473408e-03, -2.24453839e-03,\n",
              "         -6.37438148e-03, -6.89191837e-03, -8.36847816e-03,\n",
              "         -2.00259052e-02,  5.75169642e-03, -1.04182778e-04,\n",
              "          8.30205623e-03,  2.85149063e-03,  7.31676468e-04,\n",
              "         -3.80880688e-03, -4.72008577e-03,  1.05240028e-02,\n",
              "         -5.37816714e-03,  4.57428442e-03,  3.31566407e-04,\n",
              "          7.69949751e-03, -1.44334161e-03, -1.09555190e-02,\n",
              "          5.52681973e-03,  3.27096903e-03,  2.58923159e-03,\n",
              "          6.96677761e-03, -1.40823349e-02, -1.13577899e-02,\n",
              "          1.88334659e-03, -7.86080898e-04,  3.41488840e-03,\n",
              "         -6.09263638e-03,  1.06652090e-02],\n",
              "        [ 3.25317518e-03, -6.37360848e-04, -1.35551915e-02,\n",
              "          1.11864526e-02, -1.26234628e-02, -2.09110603e-03,\n",
              "         -1.59078110e-02, -1.44892861e-03,  8.99522845e-03,\n",
              "         -6.69160578e-03,  5.79454517e-03, -4.89070965e-03,\n",
              "          2.16350518e-03, -2.80009722e-03, -4.61498043e-04,\n",
              "         -6.39927923e-04,  6.26850221e-03, -6.27830438e-03,\n",
              "          5.86332195e-03,  5.37145417e-03, -5.84151642e-03,\n",
              "          4.85426420e-03,  7.48062460e-03,  1.15835015e-03,\n",
              "          9.32221208e-03, -9.34766419e-03, -1.77218113e-02,\n",
              "          1.08341349e-03,  2.01156712e-03, -2.15689768e-03,\n",
              "         -7.36237969e-03,  3.53409606e-03],\n",
              "        [ 7.10051227e-03,  6.61383383e-03, -1.26682324e-02,\n",
              "          1.81150567e-02, -1.45073887e-02, -3.14523885e-03,\n",
              "         -1.72523633e-02, -2.90347124e-03,  1.48372343e-02,\n",
              "         -1.41830361e-02,  1.10098291e-02, -1.26083707e-02,\n",
              "         -9.71558969e-04, -1.03756634e-03, -8.66568089e-03,\n",
              "         -3.16876103e-03,  9.13463254e-03, -1.21105937e-02,\n",
              "         -1.32374361e-03,  6.88985921e-03,  4.88685258e-03,\n",
              "          7.52960239e-03,  1.03634689e-02, -7.00717501e-04,\n",
              "          1.12743080e-02, -8.69119447e-03, -1.12190116e-02,\n",
              "          7.41458824e-03,  1.22981723e-02, -6.25261292e-03,\n",
              "         -2.40020934e-04,  2.06769723e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_type='luong'):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.attention_type = attention_type    \n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    self.attention_mechanism = tfa.seq2seq.LuongAttention(\n",
        "        units  = dec_units, \n",
        "        memory = memory,  # The memory to query; RNN encoder output sequence.\n",
        "        memory_sequence_length = memory_sequence_length  # valid length mask\n",
        "    )\n",
        "\n",
        "    self.decoder = tfa.seq2seq.BasicDecoder(\n",
        "        cell    = tfa.seq2seq.AttentionWrapper(\n",
        "            cell                 = tf.keras.layers.GRUCell(self.dec_units),\n",
        "            attention_mechanism  = self.attention_mechanism,\n",
        "            attention_layer_size = self.dec_units\n",
        "            ),\n",
        "        sampler = tfa.seq2seq.sampler.TrainingSampler(),\n",
        "        output_layer=self.fc\n",
        "    )\n",
        "\n",
        "\n",
        "    ## Decoder RNN \n",
        "    self.decoder_rnn_cell = \n",
        "   \n",
        "    # Sampler\n",
        "    self.sampler = \n",
        "\n",
        "    # Create attention mechanism with memory = None\n",
        "    self.attention_mechanism = self.build_attention_mechanism(self.dec_units, None, self.batch_sz*[max_length_input], self.attention_type)\n",
        "\n",
        "    ### Wrap Attention mechanism with the decoder RNN\n",
        "    self.rnn_cell = self.build_rnn_cell(batch_sz)\n",
        "\n",
        "    ### Define the decoder with respect to fundamental rnn cell\n",
        "    self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler=self.sampler, output_layer=self.fc)\n",
        "\n",
        "    \n",
        "  ''' def build_rnn_cell(self, batch_sz):\n",
        "    rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, \n",
        "                                  self.attention_mechanism, attention_layer_size=self.dec_units)\n",
        "    return rnn_cell '''\n",
        "\n",
        "  def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n",
        "    # ------------- #\n",
        "    # typ: Which sort of attention (Bahdanau, Luong)\n",
        "    # dec_units: final dimension of attention outputs \n",
        "    # memory: encoder hidden states of shape (batch_size, max_length_input, enc_units)\n",
        "    # memory_sequence_length: 1d array of shape (batch_size) with every element set to max_length_input (for masking purpose)\n",
        "    return \n",
        "\n",
        "  def build_initial_state(self, batch_sz, encoder_state, Dtype):\n",
        "    decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_sz, dtype=Dtype)\n",
        "    decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
        "    return decoder_initial_state\n",
        "\n",
        "\n",
        "  def call(self, inputs, initial_state):\n",
        "    x = self.embedding(inputs)\n",
        "    outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=self.batch_sz*[max_length_output])\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "DF9TuwBsA5qc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d93BTTgUXXjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test decoder stack\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 'luong')\n",
        "sample_x = tf.random.uniform((BATCH_SIZE, max_length_output))\n",
        "decoder.attention_mechanism.setup_memory(sample_output)\n",
        "initial_state = decoder.build_initial_state(BATCH_SIZE, sample_h, tf.float32)\n",
        "\n",
        "\n",
        "sample_decoder_outputs = decoder(sample_x, initial_state)\n",
        "\n",
        "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoomdYEJO06o",
        "outputId": "73879da7-e411-4375-a64c-85267ea802ed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder Outputs Shape:  (64, 930, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ids4G1gjPnWi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}